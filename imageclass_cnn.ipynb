{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb23874-06b6-456f-bde4-99e5ab0c64cb",
   "metadata": {},
   "source": [
    "# 1. SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc939bf-3b2f-4b76-8dd8-50fae22e9fc8",
   "metadata": {},
   "source": [
    "## 1.1 Import of needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2eceb548-39f1-421e-9aac-03cb10c481fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e184766-c691-4f09-9473-81906d93cf28",
   "metadata": {},
   "source": [
    "## 1.2 Basic transformations to all incoming data \n",
    "RGB values scaled to values between 0 and 1, data transformed into tensor datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "befab1c3-219a-44ff-8c2c-c917b4f8d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #transformation into tensor datatype, also converting RGB into the 0-1 range\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #normalize with a mean of 0.5 and a standard deviation of 0.5 to get values between -1 to 1 (better range to work with)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ac862-2c10-4420-ba68-5a4cd51dce03",
   "metadata": {},
   "source": [
    "## 1.3 Importing train/testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d46334d-1286-498f-9a49-eeabce938dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True) #downloading data from the CIFAR10 dataset and labelling it as train/test data\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2) #loading the data from created directory in shuffled batches of size 32, 2 parallel workers -> faster\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3556dc3-0725-4a6e-930a-52be28bd5921",
   "metadata": {},
   "source": [
    "## 1.4 Checking the structure of incoming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "42e8a72b-fe09-4530-bb8e-542b67bad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "29b7f88e-3997-465c-873b-7acf1b5acbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size() #output meaning: 3 channels (RGB), image resolution 32x32 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c0cb8-b456-4add-ba1f-dd05e6d571e7",
   "metadata": {},
   "source": [
    "## 1.5 Defining classes of output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "115fa8a2-26cb-4271-82c9-89b14b0989fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] #labels for output classes, CNN output will be an integer from 0-9 corresponding to these labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b1f5d-24a2-48cc-985a-ef9fe02d29f3",
   "metadata": {},
   "source": [
    "# 2.0 Building the Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4db237-a7c0-4f8d-b55a-799981ebb191",
   "metadata": {},
   "source": [
    "## 2.1 Creating the CNN class\n",
    "Within the init method layers can be added and values can be changed except for the 3 input channels and the 10 output neurons/classes, note that all numbers must be compatible with previous steps and therefore calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b88d194-f818-4cf8-b5f1-bc5df6610620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module): #base class from pytorch for a neural network\n",
    "    \n",
    "    def __init__(self): #constructor method for defining the structure\n",
    "        super().__init__() #to be able to call __init__ method of parent class\n",
    "\n",
    "        #convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5) #defining arguments of applied convolution: 3 for input channels RGB, 12 for the amount of the created feature maps, kernel size of 5x5 producing the feature maps\n",
    "                                         #calculation of output shape: (input size - kernel size) / kernel stride + 1(?) so (32-5) / 1 + 1 = 28 leads to outputs of (12, 28, 28) or 12 28x28p feature maps\n",
    "        #pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2) #reshaping the convolution output by the average value of grids of 2x2 pixels, leading to a new shape of (12, 14, 14)\n",
    "\n",
    "        #second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5) #creating 24 feature maps from the 12 created before with kernel size of 5x5 -> new shape: (24, 10, 10), second pooling step made in later defined forward logic\n",
    "\n",
    "        #first dense or fully connected layer (these include weights/biases?)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120) #multiplication to flatten the shape, 120 neurons as outputs\n",
    "        #second fc layer\n",
    "        self.fc2 = nn.Linear(120, 84) #120 neurons connecting to 84 neurons\n",
    "        #third fc layer\n",
    "        self.fc3 = nn.Linear(84, 10) #84 neurons connecting to the amount of neurons corresponding to the desired amount output possibilities\n",
    "\n",
    "    \n",
    "    def forward(self, x): #x being the input which the forward method applies the formerly defined layers onto\n",
    "        x = self.pool(F.relu(self.conv1(x))) #pooling the result of the ReLU activation function (for breaking linearity) applied to the first convolution of input x\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x)) #applying ReLU to the input passing connected layers\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598f227-c015-4d90-97d2-d7009703bf9d",
   "metadata": {},
   "source": [
    "## 2.2 Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d513ecb-ede1-4f44-902c-74e0029d7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss() #TODO - what exactly is a loss function doing\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #applying Stochastic Gradiant Descent momentum optimization on params of the net, learning rate = 0.001 - TODO what is an optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f59abc-2b45-4105-8b32-d5d1c87d3769",
   "metadata": {},
   "source": [
    "## 2.3 Defining epochs\n",
    "Epochs are the training cycles the network repeats to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "69b59093-e090-4281-8c4b-a57c8a507544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss: 2.2138\n",
      "Training epoch 1...\n",
      "Loss: 1.8036\n",
      "Training epoch 2...\n",
      "Loss: 1.5385\n",
      "Training epoch 3...\n",
      "Loss: 1.4076\n",
      "Training epoch 4...\n",
      "Loss: 1.3155\n",
      "Training epoch 5...\n",
      "Loss: 1.2404\n",
      "Training epoch 6...\n",
      "Loss: 1.1679\n",
      "Training epoch 7...\n",
      "Loss: 1.1067\n",
      "Training epoch 8...\n",
      "Loss: 1.0518\n",
      "Training epoch 9...\n",
      "Loss: 1.0033\n",
      "Training epoch 10...\n",
      "Loss: 0.9637\n",
      "Training epoch 11...\n",
      "Loss: 0.9215\n",
      "Training epoch 12...\n",
      "Loss: 0.8919\n",
      "Training epoch 13...\n",
      "Loss: 0.8517\n",
      "Training epoch 14...\n",
      "Loss: 0.8216\n",
      "Training epoch 15...\n",
      "Loss: 0.7854\n",
      "Training epoch 16...\n",
      "Loss: 0.7585\n",
      "Training epoch 17...\n",
      "Loss: 0.7302\n",
      "Training epoch 18...\n",
      "Loss: 0.7047\n",
      "Training epoch 19...\n",
      "Loss: 0.6812\n",
      "Training epoch 20...\n",
      "Loss: 0.6551\n",
      "Training epoch 21...\n",
      "Loss: 0.6312\n",
      "Training epoch 22...\n",
      "Loss: 0.6046\n",
      "Training epoch 23...\n",
      "Loss: 0.5845\n",
      "Training epoch 24...\n",
      "Loss: 0.5642\n",
      "Training epoch 25...\n",
      "Loss: 0.5476\n",
      "Training epoch 26...\n",
      "Loss: 0.5176\n",
      "Training epoch 27...\n",
      "Loss: 0.4987\n",
      "Training epoch 28...\n",
      "Loss: 0.4797\n",
      "Training epoch 29...\n",
      "Loss: 0.4611\n",
      "Training epoch 30...\n",
      "Loss: 0.4426\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(31):\n",
    "    print(f'Training epoch {epoch}...') #printing the current cycle\n",
    "\n",
    "    running_loss = 0.0 #for adding up and keeping track of the loss\n",
    "\n",
    "    for i, data in enumerate(train_loader): #getting batches from the train loader\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad() #resetting the gradiants to none\n",
    "\n",
    "        outputs = net(inputs) #feeding the inputs to the network\n",
    "\n",
    "        loss = loss_function(outputs, labels) #feeding these calculated outputs and desired outputs/labels to the loss function\n",
    "        loss.backward() #calling backpropagation on the gotten loss, already implemented in pytorch\n",
    "        optimizer.step() #a 'step forward' depending on the learning rate\n",
    "\n",
    "        running_loss += loss.item() #saving tensor values in the track keeping variable\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}') #printing out the average loss calculated above all made steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362e3d9-ed0d-45fc-9261-b33a57b8f2ec",
   "metadata": {},
   "source": [
    "## 2.4 Saving parameters\n",
    "This is just saving all important data of the trained CNN so no need to train every time before using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd17a101-cd8a-4c26-960f-3218011194f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e1680bc-6a94-48f2-ab7d-254d68e9d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21372\\384279683.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('trained_net.pth')) #loading the previously calculated data as parameters for the new net instance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet() #creating a new instance of neural network\n",
    "net.load_state_dict(torch.load('trained_net.pth')) #loading the previously calculated data as parameters for the new net instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f8c42-402b-44ba-b428-60748e58445c",
   "metadata": {},
   "source": [
    "## 2.5 Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22a1d9a0-25bb-464e-b988-9431160302d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.38%\n"
     ]
    }
   ],
   "source": [
    "correct = 0 #keeping track of the correctly classified data\n",
    "total = 0\n",
    "\n",
    "net.eval() #network set to evaluation mode\n",
    "\n",
    "with torch.no_grad(): #disabling gradiant computation since there is no training here, just feeding input\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images) #saving the output of the 32 image batches fed to the network\n",
    "        _, predicted = torch.max(outputs, 1) #extracting the one value of all outputs with the highest activation, so the prediction made\n",
    "        total += labels.size(0) #32 in this case due to set batch size\n",
    "        correct += (predicted == labels).sum().item() #saving the sum of predicitons equal to labels, so the correct classifications made\n",
    "\n",
    "accuracy = 100 * correct / total #calculating overall accuracy\n",
    "\n",
    "print (f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc4d9e-080b-442f-8e34-4fcb976343a6",
   "metadata": {},
   "source": [
    "# 3.0 Testing on new images\n",
    "Setup to be able to load new images not included in the dataset for actual testing with unknown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8453704c-0fae-49c0-ad2c-efb8c1d479d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: car\n",
      "Prediction: frog\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([ #transformation made to input images to fit in the used format\n",
    "    transforms.Resize((32, 32)), #resizing input images to 32x32 pixels\n",
    "    transforms.ToTensor(), #transforming into tensor datatype\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image) #applying transformation onto given input images\n",
    "    image = image.unsqueeze(0) #adding batch dimension for the input for the correct input shape (even if its only 1 image)\n",
    "    return image\n",
    "\n",
    "image_archive = [] #loading all images with .png datatype out of a folder into a list\n",
    "for filename in glob.glob('./unseen_images/*.png'):\n",
    "    im = load_image(filename)\n",
    "    image_archive.append(im)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for image in image_archive:\n",
    "        output = net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction: {class_names[predicted.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc38c3-9e81-4ca8-9521-5edfae8385c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
